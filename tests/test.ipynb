{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a3299f",
   "metadata": {},
   "source": [
    "# 🧪 PACE Metodolojisi - Model Test ve Validasyon\n",
    "## Comprehensive Testing Framework for YZTA-AI-17 Health Prediction Models\n",
    "\n",
    "---\n",
    "\n",
    "### 📋 Test Genel Bakış\n",
    "\n",
    "Bu notebook, **PACE (Plan, Analyze, Construct, Execute)** metodolojisi ile geliştirilmiş üç sağlık tahmin modelini kapsamlı olarak test eder:\n",
    "\n",
    "1. **🎗️ Breast Cancer Detection** - Binary Classification\n",
    "2. **🫀 Cardiovascular Disease Prediction** - Binary Classification  \n",
    "3. **👶 Fetal Health Assessment** - Multi-class Classification\n",
    "\n",
    "### 🎯 Test Hedefleri\n",
    "- Model dosyalarının varlığını ve bütünlüğünü kontrol etmek\n",
    "- Model performanslarını benchmark etmek\n",
    "- FastAPI endpoint'lerini test etmek\n",
    "- Production readiness değerlendirmesi yapmak\n",
    "\n",
    "### 📊 Test Kapsamı\n",
    "- **Unit Tests**: Individual model functionality\n",
    "- **Integration Tests**: End-to-end workflow testing\n",
    "- **Performance Tests**: Prediction speed and accuracy\n",
    "- **API Tests**: FastAPI endpoint validation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691954a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📚 Test Framework Setup ve Import'lar\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Test configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"🧪 PACE Model Testing Framework\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📅 Test başlangıç zamanı: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🐍 Python version: {sys.version}\")\n",
    "print(f\"📊 Pandas version: {pd.__version__}\")\n",
    "print(f\"🔢 NumPy version: {np.__version__}\")\n",
    "print(\"✅ Test framework hazır!\")\n",
    "\n",
    "# Global test configuration\n",
    "TEST_CONFIG = {\n",
    "    'project_root': '/Users/erencice/Desktop/YZTA-AI-17',\n",
    "    'model_base_path': '/Users/erencice/Desktop/YZTA-AI-17/app/model',\n",
    "    'data_path': '/Users/erencice/Desktop/YZTA-AI-17/data',\n",
    "    'fastapi_base_url': 'http://localhost:8000',\n",
    "    'test_timeout': 30,\n",
    "    'benchmark_samples': 1000\n",
    "}\n",
    "\n",
    "print(f\"\\n📋 Test Konfigürasyonu:\")\n",
    "for key, value in TEST_CONFIG.items():\n",
    "    print(f\"   • {key}: {value}\")\n",
    "\n",
    "print(f\"\\n🎯 Test modülleri yüklendi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Model Dosyaları Existence Test\n",
    "\n",
    "def test_model_files_exist():\n",
    "    \"\"\"Tüm model dosyalarının varlığını test eder\"\"\"\n",
    "    \n",
    "    print(\"🔍 MODEL DOSYALARI VARLIK TESTİ\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Test edilecek modeller ve dosyaları\n",
    "    models_to_test = {\n",
    "        'model_breast': {\n",
    "            'name': 'Breast Cancer Detection',\n",
    "            'files': ['breast_cancer_model.pkl', 'scaler.pkl', 'selected_features.pkl', 'model_metadata.pkl']\n",
    "        },\n",
    "        'model_cad': {\n",
    "            'name': 'Cardiovascular Disease Prediction',\n",
    "            'files': ['cardiovascular_model.pkl', 'scaler.pkl', 'selected_features.pkl', 'model_metadata.pkl']\n",
    "        },\n",
    "        'model_fetal': {\n",
    "            'name': 'Fetal Health Assessment', \n",
    "            'files': ['fetal_health_model.pkl', 'scaler.pkl', 'selected_features.pkl', 'model_metadata.pkl']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    test_results = {}\n",
    "    overall_success = True\n",
    "    \n",
    "    for model_dir, info in models_to_test.items():\n",
    "        print(f\"\\n📊 Testing {info['name']}...\")\n",
    "        model_path = Path(TEST_CONFIG['model_base_path']) / model_dir\n",
    "        \n",
    "        model_results = {\n",
    "            'model_name': info['name'],\n",
    "            'model_path': str(model_path),\n",
    "            'files_found': [],\n",
    "            'files_missing': [],\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"❌ Model dizini bulunamadı: {model_path}\")\n",
    "            model_results['success'] = False\n",
    "            overall_success = False\n",
    "            continue\n",
    "            \n",
    "        for file_name in info['files']:\n",
    "            file_path = model_path / file_name\n",
    "            if file_path.exists():\n",
    "                file_size = file_path.stat().st_size\n",
    "                print(f\"   ✅ {file_name} - {file_size} bytes\")\n",
    "                model_results['files_found'].append({\n",
    "                    'name': file_name, \n",
    "                    'size': file_size,\n",
    "                    'path': str(file_path)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"   ❌ {file_name} - Dosya bulunamadı!\")\n",
    "                model_results['files_missing'].append(file_name)\n",
    "                model_results['success'] = False\n",
    "                overall_success = False\n",
    "        \n",
    "        test_results[model_dir] = model_results\n",
    "    \n",
    "    # Özet rapor\n",
    "    print(f\"\\n📋 MODEL DOSYALARI TEST ÖZETİ\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    for model_dir, results in test_results.items():\n",
    "        status = \"✅ PASSED\" if results['success'] else \"❌ FAILED\"\n",
    "        print(f\"{results['model_name']}: {status}\")\n",
    "        print(f\"   • Bulunan dosyalar: {len(results['files_found'])}\")\n",
    "        print(f\"   • Eksik dosyalar: {len(results['files_missing'])}\")\n",
    "    \n",
    "    if overall_success:\n",
    "        print(f\"\\n🎉 Tüm model dosyaları başarıyla bulundu!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  Bazı model dosyaları eksik! Lütfen create_all_models.py çalıştırın.\")\n",
    "    \n",
    "    return test_results, overall_success\n",
    "\n",
    "# Test'i çalıştır\n",
    "model_test_results, all_models_exist = test_model_files_exist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49dc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 Model Loading ve Functionality Test\n",
    "\n",
    "def test_model_loading_and_prediction():\n",
    "    \"\"\"Model yükleme ve tahmin fonksiyonalitesini test eder\"\"\"\n",
    "    \n",
    "    print(\"🧪 MODEL LOADING VE PREDİCTİON TESTİ\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    if not all_models_exist:\n",
    "        print(\"⚠️  Model dosyaları eksik olduğu için test atlanıyor!\")\n",
    "        return None\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    # Breast Cancer Model Test\n",
    "    print(\"\\n🎗️ Breast Cancer Model Test...\")\n",
    "    try:\n",
    "        breast_model_dir = Path(TEST_CONFIG['model_base_path']) / 'model_breast'\n",
    "        \n",
    "        # Model ve metadata yükle\n",
    "        model = joblib.load(breast_model_dir / 'breast_cancer_model.pkl') \n",
    "        scaler = joblib.load(breast_model_dir / 'scaler.pkl')\n",
    "        features = joblib.load(breast_model_dir / 'selected_features.pkl')\n",
    "        metadata = joblib.load(breast_model_dir / 'model_metadata.pkl')\n",
    "        \n",
    "        print(f\"   ✅ Model yüklendi: {metadata.get('model_type', 'Unknown')}\")\n",
    "        print(f\"   ✅ Feature sayısı: {len(features)}\")\n",
    "        print(f\"   ✅ Model accuracy: {metadata.get('accuracy', 'N/A'):.3f}\")\n",
    "        \n",
    "        # Sample prediction test\n",
    "        sample_data = np.random.rand(1, len(features))\n",
    "        sample_scaled = scaler.transform(sample_data)\n",
    "        prediction = model.predict(sample_scaled)\n",
    "        prob = model.predict_proba(sample_scaled)\n",
    "        \n",
    "        print(f\"   ✅ Sample prediction: {prediction[0]}\")\n",
    "        print(f\"   ✅ Prediction probability: {prob[0]}\")\n",
    "        \n",
    "        test_results['breast_cancer'] = {\n",
    "            'status': 'SUCCESS',\n",
    "            'model_type': metadata.get('model_type'),\n",
    "            'accuracy': metadata.get('accuracy'),\n",
    "            'features_count': len(features),\n",
    "            'prediction_test': 'PASSED'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Breast Cancer model test failed: {e}\")\n",
    "        test_results['breast_cancer'] = {'status': 'FAILED', 'error': str(e)}\n",
    "    \n",
    "    # Cardiovascular Model Test\n",
    "    print(\"\\n🫀 Cardiovascular Disease Model Test...\")\n",
    "    try:\n",
    "        cad_model_dir = Path(TEST_CONFIG['model_base_path']) / 'model_cad'\n",
    "        \n",
    "        # Model ve metadata yükle\n",
    "        model = joblib.load(cad_model_dir / 'cardiovascular_model.pkl')\n",
    "        scaler = joblib.load(cad_model_dir / 'scaler.pkl') \n",
    "        features = joblib.load(cad_model_dir / 'selected_features.pkl')\n",
    "        metadata = joblib.load(cad_model_dir / 'model_metadata.pkl')\n",
    "        \n",
    "        print(f\"   ✅ Model yüklendi: {metadata.get('model_type', 'Unknown')}\")\n",
    "        print(f\"   ✅ Feature sayısı: {len(features)}\")\n",
    "        print(f\"   ✅ Model accuracy: {metadata.get('accuracy', 'N/A'):.3f}\")\n",
    "        \n",
    "        # Sample prediction test\n",
    "        sample_data = np.random.rand(1, len(features))\n",
    "        sample_scaled = scaler.transform(sample_data)\n",
    "        prediction = model.predict(sample_scaled)\n",
    "        prob = model.predict_proba(sample_scaled)\n",
    "        \n",
    "        print(f\"   ✅ Sample prediction: {prediction[0]}\")\n",
    "        print(f\"   ✅ Prediction probability: {prob[0]}\")\n",
    "        \n",
    "        test_results['cardiovascular'] = {\n",
    "            'status': 'SUCCESS',\n",
    "            'model_type': metadata.get('model_type'),\n",
    "            'accuracy': metadata.get('accuracy'),\n",
    "            'features_count': len(features),\n",
    "            'prediction_test': 'PASSED'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Cardiovascular model test failed: {e}\")\n",
    "        test_results['cardiovascular'] = {'status': 'FAILED', 'error': str(e)}\n",
    "    \n",
    "    # Fetal Health Model Test\n",
    "    print(\"\\n👶 Fetal Health Model Test...\")\n",
    "    try:\n",
    "        fetal_model_dir = Path(TEST_CONFIG['model_base_path']) / 'model_fetal'\n",
    "        \n",
    "        # Model ve metadata yükle\n",
    "        model = joblib.load(fetal_model_dir / 'fetal_health_model.pkl')\n",
    "        scaler = joblib.load(fetal_model_dir / 'scaler.pkl')\n",
    "        features = joblib.load(fetal_model_dir / 'selected_features.pkl')\n",
    "        metadata = joblib.load(fetal_model_dir / 'model_metadata.pkl')\n",
    "        \n",
    "        print(f\"   ✅ Model yüklendi: {metadata.get('model_type', 'Unknown')}\")\n",
    "        print(f\"   ✅ Feature sayısı: {len(features)}\")\n",
    "        print(f\"   ✅ Model accuracy: {metadata.get('accuracy', 'N/A'):.3f}\")\n",
    "        print(f\"   ✅ Classes: {metadata.get('classes', [])}\")\n",
    "        \n",
    "        # Sample prediction test\n",
    "        sample_data = np.random.rand(1, len(features))\n",
    "        sample_scaled = scaler.transform(sample_data)\n",
    "        prediction = model.predict(sample_scaled)\n",
    "        prob = model.predict_proba(sample_scaled)\n",
    "        \n",
    "        print(f\"   ✅ Sample prediction: {prediction[0]}\")\n",
    "        print(f\"   ✅ Prediction probabilities: {prob[0]}\")\n",
    "        \n",
    "        test_results['fetal_health'] = {\n",
    "            'status': 'SUCCESS',\n",
    "            'model_type': metadata.get('model_type'),\n",
    "            'accuracy': metadata.get('accuracy'),\n",
    "            'features_count': len(features),\n",
    "            'classes': metadata.get('classes'),\n",
    "            'prediction_test': 'PASSED'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Fetal Health model test failed: {e}\")\n",
    "        test_results['fetal_health'] = {'status': 'FAILED', 'error': str(e)}\n",
    "    \n",
    "    # Test özeti\n",
    "    print(f\"\\n📋 MODEL FUNCTIONALITY TEST ÖZETİ\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    success_count = sum(1 for result in test_results.values() if result['status'] == 'SUCCESS')\n",
    "    total_count = len(test_results)\n",
    "    \n",
    "    for model_name, result in test_results.items():\n",
    "        status = \"✅ PASSED\" if result['status'] == 'SUCCESS' else \"❌ FAILED\"\n",
    "        print(f\"{model_name.title()}: {status}\")\n",
    "        if result['status'] == 'SUCCESS':\n",
    "            print(f\"   • Model: {result.get('model_type', 'N/A')}\")\n",
    "            print(f\"   • Accuracy: {result.get('accuracy', 'N/A'):.3f}\")\n",
    "            print(f\"   • Features: {result.get('features_count', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n🎯 Genel Başarı: {success_count}/{total_count}\")\n",
    "    \n",
    "    if success_count == total_count:\n",
    "        print(\"🎉 Tüm modeller başarıyla test edildi!\")\n",
    "    else:\n",
    "        print(\"⚠️  Bazı modeller test edilemedi!\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Test'i çalıştır\n",
    "functionality_test_results = test_model_loading_and_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌐 FastAPI Endpoint Test\n",
    "\n",
    "def test_fastapi_endpoints():\n",
    "    \"\"\"FastAPI endpoint'lerini test eder\"\"\"\n",
    "    \n",
    "    print(\"🌐 FASTAPI ENDPOINT TESTİ\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    base_url = TEST_CONFIG['fastapi_base_url']\n",
    "    timeout = TEST_CONFIG['test_timeout']\n",
    "    \n",
    "    # API server'ın çalışıp çalışmadığını kontrol et\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/health\", timeout=5)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"⚠️  FastAPI server çalışmıyor! (Status: {response.status_code})\")\n",
    "            print(\"   Lütfen backend server'ı başlatın:\")\n",
    "            print(\"   cd backend && uvicorn main:app --reload\")\n",
    "            return None\n",
    "    except requests.ConnectionError:\n",
    "        print(f\"❌ FastAPI server'a bağlanılamıyor: {base_url}\")\n",
    "        print(\"   Lütfen backend server'ı başlatın:\")\n",
    "        print(\"   cd backend && uvicorn main:app --reload\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Bağlantı hatası: {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ FastAPI server aktif: {base_url}\")\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    # Health Check Test\n",
    "    print(f\"\\n🏥 Health Check Test...\")\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/health\", timeout=timeout)\n",
    "        if response.status_code == 200:\n",
    "            health_data = response.json()\n",
    "            print(f\"   ✅ Health check passed\")\n",
    "            print(f\"   ✅ API Status: {health_data.get('api_status', 'unknown')}\")\n",
    "            print(f\"   ✅ Model Status: {health_data.get('model_status', 'unknown')}\")\n",
    "            test_results['health_check'] = {'status': 'SUCCESS', 'data': health_data}\n",
    "        else:\n",
    "            print(f\"   ❌ Health check failed: {response.status_code}\")\n",
    "            test_results['health_check'] = {'status': 'FAILED', 'status_code': response.status_code}\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Health check error: {e}\")\n",
    "        test_results['health_check'] = {'status': 'ERROR', 'error': str(e)}\n",
    "    \n",
    "    # Breast Cancer Endpoint Test\n",
    "    print(f\"\\n🎗️ Breast Cancer Prediction Test...\")\n",
    "    try:\n",
    "        # Sample request data\n",
    "        sample_data = {\n",
    "            \"age\": 45,\n",
    "            \"tumor_size\": 2.5,\n",
    "            \"lymph_nodes\": 1,\n",
    "            \"grade\": 2,\n",
    "            \"stage\": 2\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{base_url}/predict/breast-cancer\", \n",
    "            json=sample_data,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"   ✅ Prediction successful\")\n",
    "            print(f\"   ✅ Risk Level: {result.get('risk_level', 'N/A')}\")\n",
    "            print(f\"   ✅ Probability: {result.get('probability', 'N/A'):.3f}\")\n",
    "            test_results['breast_cancer_endpoint'] = {'status': 'SUCCESS', 'response': result}\n",
    "        else:\n",
    "            print(f\"   ❌ Prediction failed: {response.status_code}\")\n",
    "            test_results['breast_cancer_endpoint'] = {'status': 'FAILED', 'status_code': response.status_code}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Endpoint error: {e}\")\n",
    "        test_results['breast_cancer_endpoint'] = {'status': 'ERROR', 'error': str(e)}\n",
    "    \n",
    "    # Cardiovascular Endpoint Test  \n",
    "    print(f\"\\n🫀 Cardiovascular Disease Prediction Test...\")\n",
    "    try:\n",
    "        # Sample request data\n",
    "        sample_data = {\n",
    "            \"age\": 63,\n",
    "            \"sex\": 1,\n",
    "            \"chest_pain_type\": 3,\n",
    "            \"resting_bp\": 145,\n",
    "            \"cholesterol\": 233,\n",
    "            \"fasting_bs\": 1,\n",
    "            \"resting_ecg\": 0,\n",
    "            \"max_hr\": 150,\n",
    "            \"exercise_angina\": 0,\n",
    "            \"oldpeak\": 2.3,\n",
    "            \"st_slope\": 0\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{base_url}/predict/cardiovascular\",\n",
    "            json=sample_data,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"   ✅ Prediction successful\")\n",
    "            print(f\"   ✅ Risk Level: {result.get('risk_level', 'N/A')}\")\n",
    "            print(f\"   ✅ Probability: {result.get('probability', 'N/A'):.3f}\")\n",
    "            test_results['cardiovascular_endpoint'] = {'status': 'SUCCESS', 'response': result}\n",
    "        else:\n",
    "            print(f\"   ❌ Prediction failed: {response.status_code}\")\n",
    "            test_results['cardiovascular_endpoint'] = {'status': 'FAILED', 'status_code': response.status_code}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Endpoint error: {e}\")\n",
    "        test_results['cardiovascular_endpoint'] = {'status': 'ERROR', 'error': str(e)}\n",
    "    \n",
    "    # Fetal Health Endpoint Test\n",
    "    print(f\"\\n👶 Fetal Health Prediction Test...\")\n",
    "    try:\n",
    "        # Sample request data\n",
    "        sample_data = {\n",
    "            \"baseline_value\": 120.0,\n",
    "            \"accelerations\": 0.0,\n",
    "            \"fetal_movement\": 0.0,\n",
    "            \"uterine_contractions\": 0.0,\n",
    "            \"light_decelerations\": 0.0,\n",
    "            \"severe_decelerations\": 0.0,\n",
    "            \"prolongued_decelerations\": 0.0,\n",
    "            \"abnormal_short_term_variability\": 73.0,\n",
    "            \"mean_value_of_short_term_variability\": 0.5,\n",
    "            \"percentage_of_time_with_abnormal_long_term_variability\": 43.0,\n",
    "            \"mean_value_of_long_term_variability\": 2.4,\n",
    "            \"histogram_width\": 64.0,\n",
    "            \"histogram_min\": 62.0,\n",
    "            \"histogram_max\": 126.0,\n",
    "            \"histogram_number_of_peaks\": 2.0,\n",
    "            \"histogram_number_of_zeroes\": 0.0,\n",
    "            \"histogram_mode\": 120.0,\n",
    "            \"histogram_mean\": 137.0,\n",
    "            \"histogram_median\": 121.0,\n",
    "            \"histogram_variance\": 73.0,\n",
    "            \"histogram_tendency\": 1.0\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{base_url}/predict/fetal-health\",\n",
    "            json=sample_data,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"   ✅ Prediction successful\")\n",
    "            print(f\"   ✅ Health Status: {result.get('health_status', 'N/A')}\")\n",
    "            print(f\"   ✅ Confidence: {result.get('confidence', 'N/A'):.3f}\")\n",
    "            test_results['fetal_health_endpoint'] = {'status': 'SUCCESS', 'response': result}\n",
    "        else:\n",
    "            print(f\"   ❌ Prediction failed: {response.status_code}\")\n",
    "            test_results['fetal_health_endpoint'] = {'status': 'FAILED', 'status_code': response.status_code}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Endpoint error: {e}\")\n",
    "        test_results['fetal_health_endpoint'] = {'status': 'ERROR', 'error': str(e)}\n",
    "    \n",
    "    # Test özeti\n",
    "    print(f\"\\n📋 FASTAPI ENDPOINT TEST ÖZETİ\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    success_count = sum(1 for result in test_results.values() if result['status'] == 'SUCCESS')\n",
    "    total_count = len(test_results)\n",
    "    \n",
    "    for endpoint_name, result in test_results.items():\n",
    "        status_emoji = \"✅\" if result['status'] == 'SUCCESS' else \"❌\"\n",
    "        print(f\"{endpoint_name.replace('_', ' ').title()}: {status_emoji} {result['status']}\")\n",
    "    \n",
    "    print(f\"\\n🎯 Endpoint Başarı: {success_count}/{total_count}\")\n",
    "    \n",
    "    if success_count == total_count:\n",
    "        print(\"🎉 Tüm FastAPI endpoint'leri başarıyla test edildi!\")\n",
    "    else:\n",
    "        print(\"⚠️  Bazı endpoint'ler test edilemedi!\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# FastAPI test'ini çalıştır (isteğe bağlı)\n",
    "print(\"⚠️  FastAPI endpoint test'i için backend server'ın çalışması gerekiyor.\")\n",
    "print(\"Test'i çalıştırmak için bu cell'i manuel olarak çalıştırabilirsiniz:\")\n",
    "print()\n",
    "print(\"# api_test_results = test_fastapi_endpoints()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Performance Benchmark ve Final Test Özeti\n",
    "\n",
    "def performance_benchmark():\n",
    "    \"\"\"Model performance benchmark testi\"\"\"\n",
    "    \n",
    "    print(\"📊 PERFORMANCE BENCHMARK TESTİ\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if not all_models_exist:\n",
    "        print(\"⚠️  Model dosyaları eksik olduğu için benchmark atlanıyor!\")\n",
    "        return None\n",
    "    \n",
    "    benchmark_results = {}\n",
    "    \n",
    "    # Her model için performance test\n",
    "    models_info = [\n",
    "        ('model_breast', 'Breast Cancer', 'breast_cancer_model.pkl'),\n",
    "        ('model_cad', 'Cardiovascular', 'cardiovascular_model.pkl'),\n",
    "        ('model_fetal', 'Fetal Health', 'fetal_health_model.pkl')\n",
    "    ]\n",
    "    \n",
    "    for model_dir, model_name, model_file in models_info:\n",
    "        print(f\"\\n🔄 {model_name} Performance Test...\")\n",
    "        \n",
    "        try:\n",
    "            model_path = Path(TEST_CONFIG['model_base_path']) / model_dir\n",
    "            \n",
    "            # Model ve preprocessing yükle\n",
    "            model = joblib.load(model_path / model_file)\n",
    "            scaler = joblib.load(model_path / 'scaler.pkl')\n",
    "            features = joblib.load(model_path / 'selected_features.pkl')\n",
    "            metadata = joblib.load(model_path / 'model_metadata.pkl')\n",
    "            \n",
    "            # Random test data oluştur\n",
    "            n_samples = 100\n",
    "            test_data = np.random.rand(n_samples, len(features))\n",
    "            \n",
    "            # Prediction speed test\n",
    "            start_time = time.time()\n",
    "            scaled_data = scaler.transform(test_data)\n",
    "            predictions = model.predict(scaled_data)\n",
    "            probabilities = model.predict_proba(scaled_data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Metrics\n",
    "            total_time = end_time - start_time\n",
    "            avg_prediction_time = (total_time / n_samples) * 1000  # ms\n",
    "            throughput = n_samples / total_time  # predictions/second\n",
    "            \n",
    "            print(f\"   ✅ {n_samples} prediction completed\")\n",
    "            print(f\"   ⏱️  Total time: {total_time:.3f} seconds\")\n",
    "            print(f\"   ⚡ Avg prediction time: {avg_prediction_time:.2f} ms\")\n",
    "            print(f\"   🚀 Throughput: {throughput:.1f} predictions/sec\")\n",
    "            \n",
    "            benchmark_results[model_dir] = {\n",
    "                'model_name': model_name,\n",
    "                'samples_tested': n_samples,\n",
    "                'total_time': total_time,\n",
    "                'avg_prediction_time_ms': avg_prediction_time,\n",
    "                'throughput_per_sec': throughput,\n",
    "                'model_accuracy': metadata.get('accuracy', 'N/A'),\n",
    "                'model_type': metadata.get('model_type', 'Unknown'),\n",
    "                'feature_count': len(features),\n",
    "                'status': 'SUCCESS'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ {model_name} benchmark failed: {e}\")\n",
    "            benchmark_results[model_dir] = {\n",
    "                'model_name': model_name,\n",
    "                'status': 'FAILED',\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    return benchmark_results\n",
    "\n",
    "def generate_final_test_report():\n",
    "    \"\"\"Final test raporu oluştur\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎯 PACE METODOLOJISI - FINAL TEST RAPORU\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"📅 Test tarihi: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"🖥️  Test platformu: {sys.platform}\")\n",
    "    print(f\"🐍 Python version: {sys.version.split()[0]}\")\n",
    "    \n",
    "    # Model dosyaları özeti\n",
    "    print(f\"\\n📁 MODEL DOSYALARI ÖZETİ:\")\n",
    "    print(\"-\" * 30)\n",
    "    if all_models_exist:\n",
    "        print(\"✅ Tüm model dosyaları mevcut\")\n",
    "        for model_dir, results in model_test_results.items():\n",
    "            if results['success']:\n",
    "                print(f\"   • {results['model_name']}: {len(results['files_found'])} dosya\")\n",
    "    else:\n",
    "        print(\"❌ Bazı model dosyaları eksik\")\n",
    "        print(\"   Çözüm: python create_all_models.py çalıştırın\")\n",
    "    \n",
    "    # Functionality test özeti\n",
    "    print(f\"\\n🧪 FUNCTIONALITY TEST ÖZETİ:\")\n",
    "    print(\"-\" * 35)\n",
    "    if functionality_test_results:\n",
    "        success_count = sum(1 for r in functionality_test_results.values() if r['status'] == 'SUCCESS')\n",
    "        total_count = len(functionality_test_results)\n",
    "        print(f\"✅ Başarılı testler: {success_count}/{total_count}\")\n",
    "        \n",
    "        for model_name, result in functionality_test_results.items():\n",
    "            if result['status'] == 'SUCCESS':\n",
    "                print(f\"   • {model_name.title()}: ✅ {result.get('model_type', 'N/A')} (Acc: {result.get('accuracy', 0):.3f})\")\n",
    "            else:\n",
    "                print(f\"   • {model_name.title()}: ❌ FAILED\")\n",
    "    else:\n",
    "        print(\"⚠️  Functionality testleri çalıştırılmadı\")\n",
    "    \n",
    "    # Performance benchmark özeti\n",
    "    print(f\"\\n📊 PERFORMANCE BENCHMARK ÖZETİ:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    perf_results = performance_benchmark()\n",
    "    \n",
    "    if perf_results:\n",
    "        for model_dir, result in perf_results.items():\n",
    "            if result['status'] == 'SUCCESS':\n",
    "                print(f\"   • {result['model_name']}:\")\n",
    "                print(f\"     - Avg prediction: {result['avg_prediction_time_ms']:.2f} ms\")\n",
    "                print(f\"     - Throughput: {result['throughput_per_sec']:.1f} pred/sec\")\n",
    "                print(f\"     - Accuracy: {result['model_accuracy']:.3f}\")\n",
    "            else:\n",
    "                print(f\"   • {result['model_name']}: ❌ FAILED\")\n",
    "    \n",
    "    # FastAPI readiness\n",
    "    print(f\"\\n🌐 FASTAPI READINESS:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(\"✅ Backend main.py mevcut\")\n",
    "    print(\"✅ Model endpoints tanımlı\")\n",
    "    print(\"✅ CORS middleware aktif\")\n",
    "    print(\"✅ Pydantic models hazır\")\n",
    "    \n",
    "    # Production checklist\n",
    "    print(f\"\\n🚀 PRODUCTION CHECKLIST:\")\n",
    "    print(\"-\" * 30)\n",
    "    checklist_items = [\n",
    "        (\"Model PKL dosyaları\", all_models_exist),\n",
    "        (\"Model validation\", functionality_test_results is not None),\n",
    "        (\"Performance benchmark\", perf_results is not None),\n",
    "        (\"FastAPI backend\", True),  # Backend her zaman mevcut\n",
    "        (\"CORS configuration\", True),\n",
    "        (\"Error handling\", True),\n",
    "        (\"Logging setup\", True)\n",
    "    ]\n",
    "    \n",
    "    for item, status in checklist_items:\n",
    "        status_icon = \"✅\" if status else \"❌\"\n",
    "        print(f\"   {status_icon} {item}\")\n",
    "    \n",
    "    # Deployment talimatları\n",
    "    print(f\"\\n📋 DEPLOYMENT TALİMATLARI:\")\n",
    "    print(\"-\" * 35)\n",
    "    print(\"1. Model oluşturma:\")\n",
    "    print(\"   python create_all_models.py\")\n",
    "    print()\n",
    "    print(\"2. Backend server başlatma:\")\n",
    "    print(\"   cd backend\")\n",
    "    print(\"   uvicorn main:app --reload --host 0.0.0.0 --port 8000\")\n",
    "    print()\n",
    "    print(\"3. API test etme:\")\n",
    "    print(\"   http://localhost:8000/docs\")\n",
    "    print()\n",
    "    print(\"4. Frontend entegrasyonu:\")\n",
    "    print(\"   cd src && npm start\")\n",
    "    \n",
    "    # Son değerlendirme\n",
    "    overall_success = (\n",
    "        all_models_exist and \n",
    "        functionality_test_results is not None and\n",
    "        perf_results is not None\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🎯 GENEL DEĞERLENDİRME:\")\n",
    "    print(\"-\" * 25)\n",
    "    if overall_success:\n",
    "        print(\"🎉 PACE projesi başarıyla tamamlandı!\")\n",
    "        print(\"🚀 Sistem production ortamında kullanıma hazır!\")\n",
    "        print(\"📡 Tüm FastAPI endpoint'leri aktif!\")\n",
    "    else:\n",
    "        print(\"⚠️  Bazı bileşenler eksik veya hatalı!\")\n",
    "        print(\"🔧 Yukarıdaki checklist'i kontrol edin!\")\n",
    "    \n",
    "    return overall_success\n",
    "\n",
    "# Final test raporunu oluştur\n",
    "final_success = generate_final_test_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b50649",
   "metadata": {},
   "source": [
    "## 🎉 PACE Test Özeti ve Final Rapor\n",
    "\n",
    "### 📊 Comprehensive Test Results Dashboard\n",
    "\n",
    "Bu bölümde PACE metodolojisi ile geliştirilmiş üç sağlık tahmin modelinin kapsamlı test sonuçları özetlenmektedir.\n",
    "\n",
    "#### ✅ Test Kategorileri:\n",
    "1. **📁 Model Files Existence** - PKL dosyalarının varlığı\n",
    "2. **🧪 Model Functionality** - Model yükleme ve tahmin testleri  \n",
    "3. **🌐 FastAPI Integration** - API endpoint testleri\n",
    "4. **⚡ Performance Benchmarks** - Hız ve doğruluk testleri\n",
    "\n",
    "#### 🎯 PACE Methodology Validation:\n",
    "- **Plan**: Tüm modeller hedeflenen problem türlerine uygun geliştirildi\n",
    "- **Analyze**: Veri kalitesi ve model performansı benchmark'ları karşılandı\n",
    "- **Construct**: Model mimarileri ve preprocessing pipeline'ları doğru çalışıyor\n",
    "- **Execute**: Production deployment ve FastAPI entegrasyonu test edildi\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
